import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import streamlit as st
from scipy.stats import skew
from io import BytesIO
from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer
from reportlab.lib.pagesizes import A4
from reportlab.lib.styles import getSampleStyleSheet
from sklearn.preprocessing import LabelEncoder

st.set_page_config(layout="wide")
st.title("ğŸ“Š Veri Analiz AracÄ±")
st.write("Bu araÃ§ sayesinde Excel/CSV dosyanÄ±zdaki verileri kolayca inceleyebilirsiniz!")

# 1ï¸âƒ£ Dosya yÃ¼kleme
uploaded_file = st.file_uploader("ğŸ“‚ Excel veya CSV dosyanÄ±zÄ± seÃ§in", type=["csv","xlsx"])
if uploaded_file:
    if uploaded_file.name.endswith('.csv'):
        data = pd.read_csv(uploaded_file)
    else:
        data = pd.read_excel(uploaded_file)

    st.success(f"âœ… DosyanÄ±z baÅŸarÄ±yla yÃ¼klendi! ğŸ“‹ Toplam {data.shape[0]} satÄ±r ve {data.shape[1]} sÃ¼tun bulunuyor.")
    st.subheader("ğŸ“‹ Verilerinizin Ä°lk BirkaÃ§ SatÄ±rÄ±")
    st.dataframe(data.head())

    # SÃ¼tun tÃ¼rlerini ayÄ±r
    numeric_cols = data.select_dtypes(include=np.number).columns.tolist()
    categorical_cols = data.select_dtypes(exclude=np.number).columns.tolist()

    # Eksik verileri doldur
    for col in data.columns:
        if col in numeric_cols:
            data[col] = data[col].fillna(data[col].median())
        else:
            data[col] = data[col].fillna(data[col].mode()[0])

    # 2ï¸âƒ£ Eksik veri analizi
    st.subheader("âš ï¸ Hangi SÃ¼tunlarda BoÅŸ Veri Var?")
    missing = data.isna().sum()
    missing_percent = (missing/len(data))*100
    missing_df = pd.DataFrame({"BoÅŸ HÃ¼cre SayÄ±sÄ±": missing, "YÃ¼zde": missing_percent}).sort_values("YÃ¼zde", ascending=False)
    
    if missing_df[missing_df["BoÅŸ HÃ¼cre SayÄ±sÄ±"]>0].empty:
        st.success("ğŸ‰ Harika! Verilerinizde hiÃ§ boÅŸ hÃ¼cre yok.")
    else:
        st.dataframe(missing_df[missing_df["BoÅŸ HÃ¼cre SayÄ±sÄ±"]>0])

    if st.checkbox("BoÅŸ Verilerin HaritasÄ±nÄ± GÃ¶ster"):
        fig, ax = plt.subplots(figsize=(10,4))
        sns.heatmap(data.isna(), cbar=False, yticklabels=False, cmap="viridis", ax=ax)
        st.pyplot(fig)

    # 3ï¸âƒ£ Temel istatistikler
    st.subheader("ğŸ“Š Verilerinizin Ã–zeti")
    st.dataframe(data.describe(include='all').T)

    # Veri filtreleme
    st.subheader("Veri Filtreleme")
    filter_col = st.selectbox("Filtrelemek istediÄŸiniz sÃ¼tunu seÃ§in:", data.columns)
    unique_vals = data[filter_col].unique()
    selected_vals = st.multiselect("Filtrelenecek deÄŸer(ler):", unique_vals)
    if selected_vals:
        st.dataframe(data[data[filter_col].isin(selected_vals)])

    # Gruba gÃ¶re analiz
    st.subheader("ğŸ“Š Gruba GÃ¶re Analiz")
    group_col = st.selectbox("Gruplamak istediÄŸiniz sÃ¼tun:", data.columns)
    agg_func = st.selectbox("Uygulanacak fonksiyon:", ["mean", "sum", "count", "max", "min"])

    try:
        if agg_func == "count":
            grouped = data.groupby(group_col).count()   # tÃ¼m kolonlarda Ã§alÄ±ÅŸÄ±r
        else:
            grouped = data.groupby(group_col)[numeric_cols].agg(agg_func)
        st.dataframe(grouped)
    except Exception as e:
        st.error(f"Hata: {e}")

    # Veri dÃ¶nÃ¼ÅŸtÃ¼rme
    st.subheader("Kategorik Verileri SayÄ±ya Ã‡evirme")
    if len(categorical_cols) > 0:
        cat_col = st.selectbox("DÃ¶nÃ¼ÅŸtÃ¼rÃ¼lecek sÃ¼tun:", categorical_cols)
        if st.button("Label Encode"):
            le = LabelEncoder()
            data[cat_col + "_encoded"] = le.fit_transform(data[cat_col].astype(str))
            st.dataframe(data.head())
    else:
        st.info("DÃ¶nÃ¼ÅŸtÃ¼rÃ¼lecek kategorik sÃ¼tun bulunamadÄ±.")

    # SÃ¼tun seÃ§me
    st.subheader("SÃ¼tun SeÃ§me")
    selected_columns = st.multiselect("GÃ¶rmek istediÄŸiniz sÃ¼tunlarÄ± seÃ§in:", data.columns.tolist(), default=data.columns.tolist())
    st.dataframe(data[selected_columns].head())

    # 4ï¸âƒ£ SayÄ±sal sÃ¼tun analizi
    if numeric_cols:
        st.subheader("ğŸ“ˆ SayÄ±sal Verilerinizin Analizi")
        st.write("Rakamlardan oluÅŸan sÃ¼tunlarÄ±nÄ±zÄ±n detaylÄ± incelemesi:")
        
        for col in numeric_cols:
            st.markdown(f"### ğŸ“Š {col}")
            col_data = data[col].dropna()
            if len(col_data) < 2:
                st.write(f"âš ï¸ {col} sÃ¼tununda yeterli veri bulunmuyor.")
                continue
                
            # Basit istatistikler
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("En KÃ¼Ã§Ã¼k DeÄŸer", f"{col_data.min():.2f}")
            with col2:
                st.metric("En BÃ¼yÃ¼k DeÄŸer", f"{col_data.max():.2f}")
            with col3:
                st.metric("Ortalama", f"{col_data.mean():.2f}")
            with col4:
                st.metric("Ortanca DeÄŸer", f"{col_data.median():.2f}")
            
            # Grafikler
            fig, axes = plt.subplots(1,3,figsize=(18,5))
            
            # Histogram
            sns.histplot(data[col].dropna(), kde=True, ax=axes[0])
            axes[0].set_title("DeÄŸerlerin DaÄŸÄ±lÄ±mÄ±")
            axes[0].set_ylabel("SÄ±klÄ±k")
            
            # Boxplot
            sns.boxplot(x=data[col], ax=axes[1])
            axes[1].set_title("Kutu GrafiÄŸi (AykÄ±rÄ± deÄŸerleri gÃ¶sterir)")
            
            # Scatter plot
            sns.scatterplot(x=data.index,y=data[col], ax=axes[2])
            axes[2].set_title("Verilerin SÄ±ralamasÄ±")
            axes[2].set_xlabel("SatÄ±r NumarasÄ±")
            
            st.pyplot(fig)
            
            if st.checkbox("Scatter Matrix GÃ¶ster", key=f"scatter_{col}"):
                from pandas.plotting import scatter_matrix
                fig = scatter_matrix(data[numeric_cols], figsize=(12,12), diagonal='kde')
                st.pyplot(plt.gcf())

            # Basit yorumlar
            skewness = skew(col_data)
            if abs(skewness) < 0.5:
                skew_text = "Veriler dengeli daÄŸÄ±lmÄ±ÅŸ"
            elif skewness > 0.5:
                skew_text = "Veriler daha Ã§ok kÃ¼Ã§Ã¼k deÄŸerler tarafÄ±nda yoÄŸunlaÅŸmÄ±ÅŸ"
            else:
                skew_text = "Veriler daha Ã§ok bÃ¼yÃ¼k deÄŸerler tarafÄ±nda yoÄŸunlaÅŸmÄ±ÅŸ"
                
            st.info(f"ğŸ“ˆ **DaÄŸÄ±lÄ±m Yorumu:** {skew_text}")

    st.subheader("Anamoli Analizi")
    numeric_cols = data.select_dtypes(include=['number']).columns
    col = st.selectbox("Anamoli Analizi Yapilacak Sutun: ",numeric_cols)
    method = st.radio("Method:", ["Z-score","IQR"])

    if method == "Z-Score":
        mean, std = data[col].mean(), data[col].std()
        data["Z-Score"] = (data[col] - mean) / std
        anomalies = data[np.abs(data["Z-Score"]) > 3]
        st.write("Anormal Degerler (|z| > 3):")
        st.dataframe(anomalies)
    elif method == "IQR":
        Q1 = data[col].quantile(0.25)
        Q3 = data[col].quantile(0.75)
        IQR = Q3 - Q1
        lower,upper = Q1 - 1.5 * IQR, Q3 + 1.5 * IQR
        anomalies = data[(data[col] > lower) | (data[col] > upper)]
        st.write(f"Anormal deÄŸerler (IQR yÃ¶ntemi, aralÄ±k: {lower:.2f} - {upper:.2f}):")
        st.dataframe(anomalies)
        
    import matplotlib.pyplot as plt
    fig, ax = plt.subplots()
    ax.boxplot(data[col], vert=False)
    ax.set_title(f"{col} - Boxplot (Anomali Analizi)")
    st.pyplot(fig)


    # 5ï¸âƒ£ Kategorik sÃ¼tun analizi
    if categorical_cols:
        st.subheader("ğŸ“Š Metin/Kategori Verilerinizin Analizi")
        st.write("Metinlerden oluÅŸan sÃ¼tunlarÄ±nÄ±zÄ±n detaylÄ± incelemesi:")
        
        for col in categorical_cols:
            st.markdown(f"### ğŸ·ï¸ {col}")
            col_data = data[col].dropna()
            if len(col_data) == 0:
                st.write(f"âš ï¸ {col} sÃ¼tununda veri bulunmuyor.")
                continue

            # En Ã§ok tekrar eden deÄŸerler
            value_counts = data[col].value_counts()
            st.write(f"ğŸ“Š Bu sÃ¼tunda **{len(value_counts)}** farklÄ± deÄŸer var")
            st.write(f"ğŸ† En sÄ±k gÃ¶rÃ¼len: **{value_counts.index[0]}** ({value_counts.iloc[0]} kez)")

            col1, col2 = st.columns(2)
            
            with col1:
                fig, ax = plt.subplots(figsize=(8,6))
                # En fazla 10 kategori gÃ¶ster
                top_values = value_counts.head(10)
                sns.countplot(x=data[col][data[col].isin(top_values.index)], 
                            order=top_values.index, ax=ax)
                ax.set_title(f"{col} - Hangi DeÄŸer KaÃ§ Kez TekrarlanÄ±yor")
                ax.tick_params(axis='x', rotation=45)
                st.pyplot(fig)

            with col2:
                fig2, ax2 = plt.subplots(figsize=(8,8))
                top_values.plot.pie(autopct="%1.1f%%", startangle=90, ax=ax2, 
                                  colors=sns.color_palette("pastel"))
                ax2.set_ylabel("")
                ax2.set_title(f"{col} - YÃ¼zdelik DaÄŸÄ±lÄ±m")
                st.pyplot(fig2)

            st.write("ğŸ“Š **DetaylÄ± DaÄŸÄ±lÄ±m:**")
            percentage_df = pd.DataFrame({
                'DeÄŸer': value_counts.index,
                'SayÄ±': value_counts.values,
                'YÃ¼zde': (value_counts.values / len(col_data) * 100).round(1)
            })
            st.dataframe(percentage_df.head(10))


    

    # 6ï¸âƒ£ Korelasyon analizi
    if len(numeric_cols) > 1:
        st.subheader("ğŸ”— SayÄ±sal SÃ¼tunlar ArasÄ±ndaki Ä°liÅŸkiler")
        st.write("Hangi sayÄ±sal sÃ¼tunlar birbirleriyle baÄŸlantÄ±lÄ±?")
        
        corr = data[numeric_cols].corr()
        fig, ax = plt.subplots(figsize=(10,8))
        sns.heatmap(corr, annot=True, fmt=".2f", cmap="RdYlBu_r", center=0, ax=ax)
        ax.set_title("SÃ¼tunlar ArasÄ±ndaki Ä°liÅŸki HaritasÄ±\n(1'e yakÄ±n = gÃ¼Ã§lÃ¼ pozitif iliÅŸki, -1'e yakÄ±n = gÃ¼Ã§lÃ¼ negatif iliÅŸki)")
        st.pyplot(fig)
        
        # GÃ¼Ã§lÃ¼ korelasyonlarÄ± bul
        strong_corr = []
        for i in range(len(corr.columns)):
            for j in range(i+1, len(corr.columns)):
                corr_val = corr.iloc[i, j]
                if abs(corr_val) > 0.7:
                    strong_corr.append({
                        'SÃ¼tun 1': corr.columns[i],
                        'SÃ¼tun 2': corr.columns[j],
                        'Ä°liÅŸki GÃ¼cÃ¼': corr_val,
                        'Yorum': 'GÃ¼Ã§lÃ¼ pozitif iliÅŸki' if corr_val > 0 else 'GÃ¼Ã§lÃ¼ negatif iliÅŸki'
                    })
        
        if strong_corr:
            st.write("ğŸ” **GÃ¼Ã§lÃ¼ Ä°liÅŸkiler Tespit Edildi:**")
            st.dataframe(pd.DataFrame(strong_corr))
        else:
            st.info("â„¹ï¸ SÃ¼tunlar arasÄ±nda Ã§ok gÃ¼Ã§lÃ¼ bir iliÅŸki tespit edilmedi.")

    # 7ï¸âƒ£ DetaylÄ± sÃ¼tun incelemesi
    st.subheader("ğŸ” Belirli Bir SÃ¼tunu DetaylÄ± Ä°ncele")
    selected_col = st.selectbox("Ä°ncelemek istediÄŸiniz sÃ¼tunu seÃ§in", data.columns)
    if selected_col:
        st.write(f"### ğŸ“Š {selected_col} DetaylÄ± Analizi")
        
        if selected_col in numeric_cols:
            col_data = data[selected_col].dropna()
            
            # Temel istatistikler
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Ortalama", f"{col_data.mean():.2f}")
                st.metric("En KÃ¼Ã§Ã¼k", f"{col_data.min():.2f}")
            with col2:
                st.metric("Ortanca", f"{col_data.median():.2f}")
                st.metric("En BÃ¼yÃ¼k", f"{col_data.max():.2f}")
            with col3:
                st.metric("Standart Sapma", f"{col_data.std():.2f}")
                st.metric("Toplam Veri", f"{len(col_data)}")
            
            # Grafik
            fig, ax = plt.subplots(figsize=(8,5))
            sns.boxplot(x=data[selected_col], ax=ax)
            ax.set_title(f"{selected_col} - Kutu GrafiÄŸi")
            st.pyplot(fig)
            
        else:
            # Kategorik sÃ¼tun iÃ§in
            value_counts = data[selected_col].value_counts()
            st.write(f"**Toplam farklÄ± deÄŸer sayÄ±sÄ±:** {len(value_counts)}")
            
            fig, ax = plt.subplots(figsize=(10,6))
            value_counts.head(15).plot(kind='bar', ax=ax)
            ax.set_title(f"{selected_col} - En SÄ±k GÃ¶rÃ¼len DeÄŸerler")
            ax.tick_params(axis='x', rotation=45)
            st.pyplot(fig)
            
            st.dataframe(value_counts.head(20))

    # 8ï¸âƒ£ Veri filtreleme
    st.subheader("ğŸ”¹ Verilerinizi Filtreleyin")
    st.write("Belirli kriterlere gÃ¶re verilerinizi sÃ¼zÃ¼n:")
    
    filtered_data = data.copy()
    col_to_filter = st.selectbox("Filtrelemek istediÄŸiniz sÃ¼tunu seÃ§in", data.columns)
    
    if col_to_filter in numeric_cols:
        min_val = float(data[col_to_filter].min())
        max_val = float(data[col_to_filter].max())
        selected_range = st.slider(
            f"{col_to_filter} iÃ§in deÄŸer aralÄ±ÄŸÄ± seÃ§in", 
            min_val, max_val, (min_val, max_val)
        )
        filtered_data = filtered_data[
            (filtered_data[col_to_filter] >= selected_range[0]) & 
            (filtered_data[col_to_filter] <= selected_range[1])
        ]
        st.write(f"ğŸ” {selected_range[0]} ile {selected_range[1]} arasÄ±ndaki veriler gÃ¶steriliyor")
        
    else:
        unique_vals = data[col_to_filter].dropna().unique()
        selected_vals = st.multiselect(
            f"{col_to_filter} iÃ§in deÄŸerleri seÃ§in", 
            unique_vals,
            default=list(unique_vals)[:5] if len(unique_vals) > 5 else list(unique_vals)
        )
        if selected_vals:
            filtered_data = filtered_data[filtered_data[col_to_filter].isin(selected_vals)]
            st.write(f"ğŸ” SeÃ§ilen deÄŸerlere sahip veriler gÃ¶steriliyor: {', '.join(map(str, selected_vals))}")

    st.write(f"ğŸ“Š **FiltrelenmiÅŸ veri:** {filtered_data.shape[0]} satÄ±r, {filtered_data.shape[1]} sÃ¼tun")
    st.dataframe(filtered_data)

    # 9ï¸âƒ£ Ä°ndirme seÃ§enekleri
    col1, col2 = st.columns(2)
    
    with col1:
        st.download_button(
            label="ğŸ“¥ FiltrelenmiÅŸ Veriyi Excel Olarak Ä°ndir",
            data=filtered_data.to_csv(index=False).encode('utf-8'),
            file_name='filtrelenmis_veri.csv',
            mime='text/csv'
        )
    
    # ğŸ”Ÿ PDF raporu fonksiyonu
    def create_simple_pdf(df):
        buffer = BytesIO()
        doc = SimpleDocTemplate(buffer, pagesize=A4)
        styles = getSampleStyleSheet()
        elements = [
            Paragraph("ğŸ“Š Veri Analiz Raporu", styles['Title']),
            Spacer(1,12)
        ]
        
        # Veri boyutu bilgisi
        elements.append(Paragraph(f"Veri Boyutu: {df.shape[0]} satÄ±r, {df.shape[1]} sÃ¼tun", styles['Normal']))
        elements.append(Spacer(1,12))
        
        # Temel istatistikler
        elements.append(Paragraph("ğŸ“Œ Temel Ä°statistikler", styles['Heading2']))
        
        # numeric_cols ve categorical_cols artÄ±k liste tipinde olmalÄ±
        numeric_cols = df.select_dtypes(include='number').columns.tolist()
        categorical_cols = df.select_dtypes(exclude='number').columns.tolist()
        
        stats_text = f"Toplam SatÄ±r: {df.shape[0]}<br/>Toplam SÃ¼tun: {df.shape[1]}<br/>"
        if numeric_cols:
            stats_text += f"SayÄ±sal SÃ¼tun SayÄ±sÄ±: {len(numeric_cols)}<br/>"
        if categorical_cols:
            stats_text += f"Metin SÃ¼tun SayÄ±sÄ±: {len(categorical_cols)}<br/>"
        
        elements.append(Paragraph(stats_text, styles['Normal']))
        
        # PDF oluÅŸtur
        doc.build(elements)
        buffer.seek(0)
        return buffer

    with col2:
        pdf_bytes = create_simple_pdf(filtered_data)
        st.download_button(
            "ğŸ“„ Basit Raporu PDF Olarak Ä°ndir", 
            data=pdf_bytes, 
            file_name="veri_raporu.pdf", 
            mime="application/pdf"
        )

    # 1ï¸âƒ£1ï¸âƒ£ Hangi sÃ¼tun daha Ã¶nemli?
    if len(numeric_cols) > 1:
        st.subheader("ğŸ¯ Hangi SÃ¼tunlar Daha Ã–nemli?")
        st.write("Bir sÃ¼tunu hedef seÃ§in, diÄŸer sÃ¼tunlarÄ±n bu hedefle ne kadar iliÅŸkili olduÄŸunu gÃ¶relim:")
        
        target_col = st.selectbox("Hedef sÃ¼tunu seÃ§in", numeric_cols, key="target_feature")
        
        if target_col:
            # Korelasyon analizi
            correlations = []
            for col in numeric_cols:
                if col != target_col:
                    corr_val = data[col].corr(data[target_col])
                    if not pd.isna(corr_val):
                        correlations.append({
                            'SÃ¼tun': col,
                            'Ä°liÅŸki GÃ¼cÃ¼': abs(corr_val),
                            'Ä°liÅŸki YÃ¶nÃ¼': 'Pozitif' if corr_val > 0 else 'Negatif',
                            'AÃ§Ä±klama': 'GÃ¼Ã§lÃ¼' if abs(corr_val) > 0.7 else 'Orta' if abs(corr_val) > 0.3 else 'ZayÄ±f'
                        })
            
            if correlations:
                corr_df = pd.DataFrame(correlations).sort_values('Ä°liÅŸki GÃ¼cÃ¼', ascending=False)

                st.write(f"### ğŸ“Š {target_col} ile En Ã‡ok Ä°liÅŸkili SÃ¼tunlar")
                st.dataframe(corr_df)
                
                # En iliÅŸkili sÃ¼tun iÃ§in scatter plot
                if len(corr_df) > 0:
                    most_correlated = corr_df.iloc[0]['SÃ¼tun']
                    fig, ax = plt.subplots(figsize=(8,6))
                    sns.scatterplot(data=data, x=most_correlated, y=target_col, ax=ax)
                    ax.set_title(f"{most_correlated} vs {target_col} Ä°liÅŸkisi")
                    st.pyplot(fig)
                    
                    st.info(f"ğŸ’¡ **Yorum:** {most_correlated} sÃ¼tunu ile {target_col} arasÄ±nda "
                           f"{corr_df.iloc[0]['AÃ§Ä±klama'].lower()} bir {corr_df.iloc[0]['Ä°liÅŸki YÃ¶nÃ¼'].lower()} iliÅŸki var.")

    if len(numeric_cols) >= 2:
        st.subheader("ğŸ¤– Basit Makine Ã–ÄŸrenmesi")
        st.write("Verilerinizle tahmin modelleri oluÅŸturun!")
        
        # Model tÃ¼rÃ¼ seÃ§imi
        ml_type = st.radio(
            "Hangi tÃ¼r analiz yapmak istiyorsuniz?",
            ["Tahmin (Regression)", "GruplandÄ±rma (Clustering)", "SÄ±nÄ±flandÄ±rma (Classification)"]
        )
        
        if ml_type == "Tahmin (Regression)":
            st.markdown("### ğŸ“ˆ Tahmin Modeli")
            st.write("Bir sÃ¼tunu diÄŸer sÃ¼tunlara gÃ¶re tahmin etmeye Ã§alÄ±ÅŸalÄ±m!")
            
            # Hedef ve Ã¶zellik seÃ§imi
            target_col = st.selectbox("Tahmin edilecek sÃ¼tun (hedef):", numeric_cols, key="ml_target")
            feature_cols = st.multiselect(
                "Tahmin iÃ§in kullanÄ±lacak sÃ¼tunlar:", 
                [col for col in numeric_cols if col != target_col],
                default=[col for col in numeric_cols if col != target_col][:3]
            )
            
            if len(feature_cols) > 0 and st.button("ğŸš€ Model OluÅŸtur ve Test Et"):
                try:
                    from sklearn.model_selection import train_test_split
                    from sklearn.linear_model import LinearRegression
                    from sklearn.ensemble import RandomForestRegressor
                    from sklearn.metrics import mean_squared_error, r2_score
                    import numpy as np
                    
                    # Veri hazÄ±rlama
                    model_data = data[feature_cols + [target_col]].dropna()
                    if len(model_data) < 10:
                        st.error("âš ï¸ Model iÃ§in yeterli veri yok (en az 10 satÄ±r gerekli)")
                    else:
                        X = model_data[feature_cols]
                        y = model_data[target_col]
                        
                        # Train-test split
                        X_train, X_test, y_train, y_test = train_test_split(
                            X, y, test_size=0.2, random_state=42
                        )
                        
                        # Model eÄŸitimi
                        models = {
                            "Linear Regression": LinearRegression(),
                            "Random Forest": RandomForestRegressor(n_estimators=50, random_state=42)
                        }
                        
                        results = {}
                        for name, model in models.items():
                            model.fit(X_train, y_train)
                            y_pred = model.predict(X_test)
                            
                            mse = mean_squared_error(y_test, y_pred)
                            r2 = r2_score(y_test, y_pred)
                            
                            results[name] = {
                                'model': model,
                                'mse': mse,
                                'rmse': np.sqrt(mse),
                                'r2': r2,
                                'y_pred': y_pred
                            }
                        
                        # SonuÃ§larÄ± gÃ¶ster
                        st.success("âœ… Modeller baÅŸarÄ±yla eÄŸitildi!")
                        
                        # Model performanslarÄ±
                        col1, col2 = st.columns(2)
                        for i, (name, result) in enumerate(results.items()):
                            with col1 if i == 0 else col2:
                                st.metric(
                                    f"{name} - RÂ² Skoru", 
                                    f"{result['r2']:.3f}",
                                    help="1'e yakÄ±n = iyi, 0'a yakÄ±n = kÃ¶tÃ¼"
                                )
                                st.metric(
                                    f"{name} - RMSE", 
                                    f"{result['rmse']:.2f}",
                                    help="DÃ¼ÅŸÃ¼k deÄŸer = iyi"
                                )
                        
                        # En iyi modeli seÃ§
                        best_model_name = max(results.keys(), key=lambda x: results[x]['r2'])
                        best_model = results[best_model_name]
                        
                        st.success(f"ğŸ† En iyi model: **{best_model_name}** (RÂ² = {best_model['r2']:.3f})")
                        
                        # Tahmin vs GerÃ§ek grafik
                        fig, ax = plt.subplots(figsize=(8, 6))
                        ax.scatter(y_test, best_model['y_pred'], alpha=0.7)
                        ax.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
                        ax.set_xlabel(f'GerÃ§ek {target_col}')
                        ax.set_ylabel(f'Tahmin Edilen {target_col}')
                        ax.set_title(f'{best_model_name} - Tahmin vs GerÃ§ek DeÄŸerler')
                        st.pyplot(fig)
                        
                        # Feature importance (Random Forest iÃ§in)
                        if best_model_name == "Random Forest":
                            importance = best_model['model'].feature_importances_
                            importance_df = pd.DataFrame({
                                'SÃ¼tun': feature_cols,
                                'Ã–nem Derecesi': importance
                            }).sort_values('Ã–nem Derecesi', ascending=False)
                            
                            st.write("### ğŸ“Š Hangi SÃ¼tunlar Daha Ã–nemli?")
                            fig, ax = plt.subplots(figsize=(8, 5))
                            sns.barplot(data=importance_df, x='Ã–nem Derecesi', y='SÃ¼tun', ax=ax)
                            ax.set_title('SÃ¼tunlarÄ±n Tahmin GÃ¼cÃ¼')
                            st.pyplot(fig)
                            
                            st.dataframe(importance_df)
                        
                        # Basit tahmin aracÄ±
                        st.write("### ğŸ¯ Yeni DeÄŸer Tahmini")
                        st.write("AÅŸaÄŸÄ±daki deÄŸerleri girerek tahmin yapabilirsiniz:")
                        
                        user_input = {}
                        cols = st.columns(len(feature_cols))
                        for i, col in enumerate(feature_cols):
                            with cols[i]:
                                min_val = float(data[col].min())
                                max_val = float(data[col].max())
                                mean_val = float(data[col].mean())
                                user_input[col] = st.number_input(
                                    f"{col}:", 
                                    min_value=min_val,
                                    max_value=max_val,
                                    value=mean_val,
                                    step=(max_val-min_val)/100
                                )
                        
                        if st.button("ğŸ”® Tahmin Et"):
                            input_array = np.array([[user_input[col] for col in feature_cols]])
                            prediction = best_model['model'].predict(input_array)[0]
                            st.success(f"ğŸ¯ Tahmini {target_col} deÄŸeri: **{prediction:.2f}**")
                            
                            # GÃ¼ven aralÄ±ÄŸÄ±
                            confidence = "YÃ¼ksek" if best_model['r2'] > 0.7 else "Orta" if best_model['r2'] > 0.3 else "DÃ¼ÅŸÃ¼k"
                            st.info(f"ğŸ“Š Model gÃ¼venilirliÄŸi: **{confidence}** (RÂ² = {best_model['r2']:.3f})")
                            
                except ImportError:
                    st.error("âŒ Scikit-learn kÃ¼tÃ¼phanesi yÃ¼klÃ¼ deÄŸil. LÃ¼tfen 'pip install scikit-learn' komutu ile yÃ¼kleyin.")
                except Exception as e:
                    st.error(f"âŒ Hata oluÅŸtu: {str(e)}")
        
        elif ml_type == "GruplandÄ±rma (Clustering)":
            st.markdown("### ğŸ¯ Veri GruplandÄ±rma")
            st.write("Verilerinizi benzerliklerine gÃ¶re gruplara ayÄ±ralÄ±m!")
            
            # SÃ¼tun seÃ§imi
            cluster_cols = st.multiselect(
                "GruplandÄ±rma iÃ§in kullanÄ±lacak sÃ¼tunlar:",
                numeric_cols,
                default=numeric_cols[:3] if len(numeric_cols) >= 3 else numeric_cols
            )
            
            n_clusters = st.slider("KaÃ§ grup oluÅŸturulsun?", 2, 8, 3)
            
            if len(cluster_cols) >= 2 and st.button("ğŸ¯ GruplandÄ±r"):
                try:
                    from sklearn.cluster import KMeans
                    from sklearn.preprocessing import StandardScaler
                    
                    # Veri hazÄ±rlama
                    cluster_data = data[cluster_cols].dropna()
                    if len(cluster_data) < n_clusters:
                        st.error(f"âš ï¸ GruplandÄ±rma iÃ§in yeterli veri yok (en az {n_clusters} satÄ±r gerekli)")
                    else:
                        # Veriyi normalize et
                        scaler = StandardScaler()
                        scaled_data = scaler.fit_transform(cluster_data)
                        
                        # K-means uygula
                        kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
                        clusters = kmeans.fit_predict(scaled_data)
                        
                        # SonuÃ§larÄ± data'ya ekle
                        cluster_data_with_labels = cluster_data.copy()
                        cluster_data_with_labels['Grup'] = clusters
                        
                        st.success(f"âœ… Veriler {n_clusters} gruba ayrÄ±ldÄ±!")
                        
                        # Grup istatistikleri
                        st.write("### ğŸ“Š Grup Ä°statistikleri")
                        group_stats = cluster_data_with_labels.groupby('Grup').agg(['mean', 'count']).round(2)
                        st.dataframe(group_stats)
                        
                        # GÃ¶rselleÅŸtirme
                        if len(cluster_cols) >= 2:
                            fig, ax = plt.subplots(figsize=(10, 6))
                            colors = plt.cm.Set3(np.linspace(0, 1, n_clusters))
                            
                            for i in range(n_clusters):
                                cluster_points = cluster_data_with_labels[cluster_data_with_labels['Grup'] == i]
                                ax.scatter(
                                    cluster_points[cluster_cols[0]], 
                                    cluster_points[cluster_cols[1]], 
                                    c=[colors[i]], 
                                    label=f'Grup {i}',
                                    alpha=0.7
                                )
                            
                            ax.set_xlabel(cluster_cols[0])
                            ax.set_ylabel(cluster_cols[1])
                            ax.set_title(f'Veri GruplandÄ±rma SonuÃ§larÄ±')
                            ax.legend()
                            st.pyplot(fig)
                        
                        # Grup Ã¶zetleri
                        st.write("### ğŸ·ï¸ Grup Karakteristikleri")
                        for i in range(n_clusters):
                            group_data = cluster_data_with_labels[cluster_data_with_labels['Grup'] == i]
                            st.write(f"**Grup {i}** ({len(group_data)} veri noktasÄ±):")
                            
                            characteristics = []
                            for col in cluster_cols:
                                mean_val = group_data[col].mean()
                                overall_mean = cluster_data[col].mean()
                                if mean_val > overall_mean * 1.1:
                                    characteristics.append(f"YÃ¼ksek {col}")
                                elif mean_val < overall_mean * 0.9:
                                    characteristics.append(f"DÃ¼ÅŸÃ¼k {col}")
                            
                            if characteristics:
                                st.write(f"- {', '.join(characteristics)}")
                            else:
                                st.write("- Ortalama deÄŸerlere sahip")
                            
                        # Download seÃ§eneÄŸi
                        csv = cluster_data_with_labels.to_csv(index=False)
                        st.download_button(
                            "ğŸ“¥ GruplandÄ±rÄ±lmÄ±ÅŸ Veriyi Ä°ndir",
                            csv,
                            "gruplandÄ±rÄ±lmÄ±ÅŸ_veri.csv",
                            "text/csv"
                        )
                            
                except ImportError:
                    st.error("âŒ Scikit-learn kÃ¼tÃ¼phanesi yÃ¼klÃ¼ deÄŸil. LÃ¼tfen 'pip install scikit-learn' komutu ile yÃ¼kleyin.")
                except Exception as e:
                    st.error(f"âŒ Hata oluÅŸtu: {str(e)}")
        
        elif ml_type == "SÄ±nÄ±flandÄ±rma (Classification)":
            st.markdown("### ğŸ¯ SÄ±nÄ±flandÄ±rma Modeli")
            st.write("Kategorik bir sÃ¼tunu diÄŸer sÃ¼tunlara gÃ¶re tahmin etmeye Ã§alÄ±ÅŸalÄ±m!")
            
            if len(categorical_cols) == 0:
                st.warning("âš ï¸ SÄ±nÄ±flandÄ±rma iÃ§in kategorik sÃ¼tun bulunamadÄ±.")
            else:
                # Hedef ve Ã¶zellik seÃ§imi
                target_col = st.selectbox("Tahmin edilecek kategorik sÃ¼tun:", categorical_cols, key="class_target")
                feature_cols = st.multiselect(
                    "Tahmin iÃ§in kullanÄ±lacak sayÄ±sal sÃ¼tunlar:", 
                    numeric_cols,
                    default=numeric_cols[:3] if len(numeric_cols) >= 3 else numeric_cols
                )
                
                if len(feature_cols) > 0 and st.button("ğŸš€ SÄ±nÄ±flandÄ±rma Modeli OluÅŸtur"):
                    try:
                        from sklearn.model_selection import train_test_split
                        from sklearn.ensemble import RandomForestClassifier
                        from sklearn.linear_model import LogisticRegression
                        from sklearn.metrics import accuracy_score, classification_report
                        from sklearn.preprocessing import LabelEncoder
                        
                        # Veri hazÄ±rlama
                        model_data = data[feature_cols + [target_col]].dropna()
                        if len(model_data) < 20:
                            st.error("âš ï¸ SÄ±nÄ±flandÄ±rma iÃ§in yeterli veri yok (en az 20 satÄ±r gerekli)")
                        else:
                            # Kategorik deÄŸiÅŸkeni encode et
                            le = LabelEncoder()
                            y_encoded = le.fit_transform(model_data[target_col])
                            unique_classes = len(le.classes_)
                            
                            if unique_classes > 10:
                                st.warning("âš ï¸ Ã‡ok fazla kategori var. SonuÃ§lar karmaÅŸÄ±k olabilir.")
                            
                            X = model_data[feature_cols]
                            y = y_encoded
                            
                            # Train-test split
                            X_train, X_test, y_train, y_test = train_test_split(
                                X, y, test_size=0.2, random_state=42, stratify=y
                            )
                            
                            # Model eÄŸitimi
                            models = {
                                "Random Forest": RandomForestClassifier(n_estimators=50, random_state=42),
                            }
                            
                            if unique_classes == 2:  # Binary classification
                                models["Logistic Regression"] = LogisticRegression(random_state=42, max_iter=1000)
                            
                            best_accuracy = 0
                            best_model = None
                            best_model_name = ""
                            
                            for name, model in models.items():
                                model.fit(X_train, y_train)
                                y_pred = model.predict(X_test)
                                accuracy = accuracy_score(y_test, y_pred)
                                
                                if accuracy > best_accuracy:
                                    best_accuracy = accuracy
                                    best_model = model
                                    best_model_name = name
                            
                            st.success(f"âœ… En iyi model: **{best_model_name}** (DoÄŸruluk: %{best_accuracy*100:.1f})")
                            
                            # Confusion matrix
                            from sklearn.metrics import confusion_matrix
                            cm = confusion_matrix(y_test, best_model.predict(X_test))
                            
                            fig, ax = plt.subplots(figsize=(8, 6))
                            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax,
                                    xticklabels=le.classes_, yticklabels=le.classes_)
                            ax.set_title('KarÄ±ÅŸÄ±klÄ±k Matrisi')
                            ax.set_xlabel('Tahmin Edilen')
                            ax.set_ylabel('GerÃ§ek')
                            st.pyplot(fig)
                            
                            # Feature importance
                            if hasattr(best_model, 'feature_importances_'):
                                importance_df = pd.DataFrame({
                                    'SÃ¼tun': feature_cols,
                                    'Ã–nem Derecesi': best_model.feature_importances_
                                }).sort_values('Ã–nem Derecesi', ascending=False)
                                
                                st.write("### ğŸ“Š Hangi SÃ¼tunlar Daha Ã–nemli?")
                                fig, ax = plt.subplots(figsize=(8, 5))
                                sns.barplot(data=importance_df, x='Ã–nem Derecesi', y='SÃ¼tun', ax=ax)
                                ax.set_title('SÃ¼tunlarÄ±n SÄ±nÄ±flandÄ±rma GÃ¼cÃ¼')
                                st.pyplot(fig)
                            
                            # Basit tahmin aracÄ±
                            st.write("### ğŸ¯ Yeni SÄ±nÄ±flandÄ±rma Tahmini")
                            user_input = {}
                            cols = st.columns(len(feature_cols))
                            for i, col in enumerate(feature_cols):
                                with cols[i]:
                                    min_val = float(data[col].min())
                                    max_val = float(data[col].max())
                                    mean_val = float(data[col].mean())
                                    user_input[col] = st.number_input(
                                        f"{col}:", 
                                        min_value=min_val,
                                        max_value=max_val,
                                        value=mean_val,
                                        step=(max_val-min_val)/100,
                                        key=f"class_{col}"
                                    )
                            
                            if st.button("ğŸ”® SÄ±nÄ±f Tahmini"):
                                input_array = np.array([[user_input[col] for col in feature_cols]])
                                prediction = best_model.predict(input_array)[0]
                                predicted_class = le.inverse_transform([prediction])[0]
                                
                                # Prediction probability
                                if hasattr(best_model, 'predict_proba'):
                                    proba = best_model.predict_proba(input_array)[0]
                                    confidence = max(proba) * 100
                                    st.success(f"ğŸ¯ Tahmini sÄ±nÄ±f: **{predicted_class}** (GÃ¼ven: %{confidence:.1f})")
                                else:
                                    st.success(f"ğŸ¯ Tahmini sÄ±nÄ±f: **{predicted_class}**")
                                    
                    except ImportError:
                        st.error("âŒ Scikit-learn kÃ¼tÃ¼phanesi yÃ¼klÃ¼ deÄŸil. LÃ¼tfen 'pip install scikit-learn' komutu ile yÃ¼kleyin.")
                    except Exception as e:
                        st.error(f"âŒ Hata oluÅŸtu: {str(e)}")

    else:
        st.info("ğŸ¤– Makine Ã¶ÄŸrenmesi iÃ§in en az 2 sayÄ±sal sÃ¼tun gerekiyor.")



    st.success("âœ… Analiz tamamlandÄ±! SorularÄ±nÄ±z varsa dosyanÄ±zÄ±n farklÄ± bÃ¶lÃ¼mlerini inceleyebilirsiniz.")
    
    # KullanÄ±m ipuÃ§larÄ±
    with st.expander("ğŸ’¡ KullanÄ±m Ä°puÃ§larÄ±"):
        st.write("""
        **ğŸ“Š Grafikleri nasÄ±l okuyayÄ±m?**
        - **Histogram:** Hangi deÄŸerlerin ne kadar sÄ±k gÃ¶rÃ¼ldÃ¼ÄŸÃ¼nÃ¼ gÃ¶sterir
        - **Kutu GrafiÄŸi:** Verilerinizin daÄŸÄ±lÄ±mÄ±nÄ± ve aykÄ±rÄ± deÄŸerleri gÃ¶sterir
        - **Pasta GrafiÄŸi:** Kategorilerin yÃ¼zdelik daÄŸÄ±lÄ±mÄ±nÄ± gÃ¶sterir
        
        **ğŸ” Ne anlama geliyor?**
        - **Ortalama:** TÃ¼m deÄŸerlerin toplamÄ±nÄ±n veri sayÄ±sÄ±na bÃ¶lÃ¼mÃ¼
        - **Ortanca:** DeÄŸerleri sÄ±raladÄ±ÄŸÄ±nÄ±zda ortada kalan deÄŸer
        - **Ä°liÅŸki GÃ¼cÃ¼:** Ä°ki sÃ¼tunun ne kadar benzer hareket ettiÄŸi (0-1 arasÄ±)
        
        **ğŸ“ˆ Verilerimi nasÄ±l daha iyi anlayabilirim?**
        - Ã–nce boÅŸ verilerinizi kontrol edin
        - SayÄ±sal sÃ¼tunlarÄ±nÄ±zÄ±n daÄŸÄ±lÄ±mÄ±na bakÄ±n
        - Kategorik sÃ¼tunlarÄ±nÄ±zda hangi deÄŸerlerin baskÄ±n olduÄŸunu gÃ¶rÃ¼n
        - SÃ¼tunlar arasÄ±ndaki iliÅŸkileri inceleyin
        """)